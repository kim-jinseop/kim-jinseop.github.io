---
layout: single
title:  "Week4-day5"
toc: true
toc_sticky: true

use_math: true
---

CV - CNN Visualization

<br>

## [ special ]


# - Visualizing CNN
- debug와 비슷한 형태를 가지는 역할
- Filter visualization

# - Analysis of model behaviors
- Nearest neighbors
    - database 
    
- Dimensionality reduction 차원축소
    - t-SNE
    
# - Model decision explanation
- 해석

## 1. Saliency test 1
- Occlusion map

## 2. Saliency test 2
- via Backpropagation 
    - get a class score or th taget source image 
    - Backpropagate
    - Visualize the obtained gradient magnitude map
    
## 3. Class activation mapping
- CAM (Class activation mapping)
    - Global average pooling (GAP)
- Grad-CAM 

- SCOUTER
    - target이 왜 아닌지도 판단가능
    
<br>

# - AutoGrad


```python
import torch
```


```python
x = torch.randn(2, requires_grad = True)
y = x * 3
gradients = torch.tensor([100, 0.1], dtype=torch.float)
y.backward(gradients,retain_graph = True) # retain_graph = True 로 하게 되면 backward 중복사용가능
print(x.grad)
```

    tensor([300.0000,   0.3000])



```python
y.backward(gradients) # Gradients are accumulated
print(x.grad)
```

    tensor([600.0000,   0.6000])


## Autograd - grad_fn


```python
x = torch.randn(2, requires_grad = True)
y = x * 3
z = x / 2
w = x + y
w,y,z
```




    (tensor([-1.3443, 12.1666], grad_fn=<AddBackward0>),
     tensor([-1.0082,  9.1249], grad_fn=<MulBackward0>),
     tensor([-0.1680,  1.5208], grad_fn=<DivBackward0>))



## Autograd - hook: register_forward_hook
- function을 hooking 할 수 있다.


```python
import torch.nn as nn
import torch.nn.functional as F
```


```python
class SimpleNet(nn.Module) :
    def __init__(self) :
        super(SimpleNet, self).__init__()
        self.conv1 = nn.Conv2d(1, 10, 5)
        self.pool1 = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(10, 20, 5)
        self.pool2 = nn.MaxPool2d(2, 2)
        self.fc = nn.Linear(320, 50)
        self.out = nn.Linear(50, 10)
        
    def forward(self, input) :
        x = self.pool1(F.relu(self.conv1(input)))
        x = self.pool2(F.relu(self.conv2(x)))
        x = x.view(x.size(0), -1)
        x = F.relu(self.fc(x))
        x = F.relu(self.out(x))
        return x
    
def hook_func(self, input, output) :
    print('inside' + self.__class__.__name__ + 'forward')
    print('')
    print('input:', type(input))
    print('input[0]:', type(input[0]))
    print('output:', type(output))
    print('')
```


```python
net = SimpleNet()
```


```python
net.conv1.register_forward_hook(hook_func)
```




    <torch.utils.hooks.RemovableHandle at 0x14a85cfd0>




```python
net.conv2.register_forward_hook(hook_func)
```




    <torch.utils.hooks.RemovableHandle at 0x14a85ce50>




```python
input = torch.randn(1,1,28,28)
out = net(input)
```

    insideConv2dforward
    
    input: <class 'tuple'>
    input[0]: <class 'torch.Tensor'>
    output: <class 'torch.Tensor'>
    
    insideConv2dforward
    
    input: <class 'tuple'>
    input[0]: <class 'torch.Tensor'>
    output: <class 'torch.Tensor'>
    



```python
def hook_pre(self, input) :
    print('inside' + self.__class__.__name__ + 'forward')
    print('')
    print('input:', type(input))
    print('input[0]:', type(input[0]))
```


```python
net = SimpleNet()
net.conv1.register_forward_pre_hook(hook_pre)

input = torch.randn(1,1,28,28)
out = net(input)
```

    insideConv2dforward
    
    input: <class 'tuple'>
    input[0]: <class 'torch.Tensor'>



```python

```
