---
layout: single
title:  "Week1-day5."

use_math: true
---


# AI-math

<br>   

## 1. 딥러닝 학습방법 이해하기

\\( O=XW + b \\) 

### 소프트맥스 연산
- 소프트맥스 함수는 모델의 출력을 `확률로 해석`할 수 있게 변환해주는 연산
- `분류 문제`를 풀 때 선형모델과 소프트맥스 함수를 결합하여 예측
- softmax 함수를 통해 R에 있는 벡터를 확률벡터로 변환할 수 있습니다.
    - 추론을 할 때는 소프트맥스 사용하지 않고, 원 핫 벡터 사용

\\( softmax(o) = (\frac{exp(o_1)}{\sum_{k=1}^p exp(o_k)},.....,\frac{exp(o_p)}{\sum_{k=1}^p exp(o_k)}) \\)

\\( softmax(o) = softmax(Wx+b) \\)

### 신경망
- 신경망은 선형모델과 활성함수(\\( \sigma \\))를 합성한 함수

    \\( H = (\sigma(z_1),...,\sigma(z_1)) \\)

    \\( \sigma(z) = \sigma(Wx + b) \\)
    

- 다층(multi-layer) 퍼셉트론(MLP)은 `신경망이 여러층 합성`된 함수

    \\( O = Z^{(L)}\\
    H^{(\ell)} = \sigma(Z^{(\ell)})\\
    Z^{(\ell)} = H^{(\ell-1)}W^{(\ell)}+b^{(\ell)}\\
    H^{(1)} = \sigma(Z^{(1)})\\
    Z^{(1)} = XW^{(1)}+b^{(1)}\\)


##### 층을 여러겹 쌓는 이유 :  
`목적함수를 근사하는데 필요한 뉴런의 숫자가 훤씬 빨리 줄어들어 좀 더 효율적으로 학습가능`  
but 최적화는 힘들다

    

### 활성함수
- R위에 정의된 비선형 함수
- 활성함수를 쓰지 않으면 딥러닝은 선형모형과 차이가 없다 
    - 비선형근사
- 딥러닝에선 ReLU 를 많이 쓰고있다.


### 역전파 알고리즘
- 역전파 알고리즘을 이용하여 각 층에 사용된 패러미터 \\( \{W^{(\ell)}, b^{(\ell)}\}_{\ell=1}^L \\)를 학습 
- 각 층 패러미터의 그레디언트 벡터는 윗층 부터 역순으로 계산
- 원리 : 연쇄법칙(chain-rule) 기반 자동미분(auto-differentiation

<br>

## 2. 확률론
- 딥러닝은 확률론 기반의 기계학습 이론에 바탕을 둔다
- 회귀 분석에서 손실함수로 사용되는 L2노름은 예측오차의 분산을 가장 최소화하는 방향으로 학습하도록 유도
- 분류 문제에서 사용되는 교차엔트로피는 모델 예측의 불확실성을 최소화하는 방향으로 학습하도록 유도
- 분산 및 불확실성을 최소화하기 위해서는 측정하는 방법을 알아야 함  

__확률분포__ 는 데이터의 초상화
- D = 데이터 공간에서 데이터를 추출하는 분포 

### 이산확률변수 vs 연속확률변수
- 확률변수는 `확률분포 D`에 따라 `이산형(discrete)`과 `연속형(continuous)`확률변수로 구분하게 된다.
- __이산형 확률변수__는 `확률변수가 가질 수 있는 경우의 수`를 모두 고려하여 확률을 `더해서` 모델링한다.
- __연속형 확률변수__는 `데이터 공간에 정의된 확률변수의 밀도(density)`위에서 `적분을 통해` 모델링 한다.
- 결합분포 P(x,y)는 D를 모델링한다.

### 조건부확률과 기계학습
- 조건부확률 P(y|x)는 입력변수 x에 대해 정답이 y일 확률을 의미한다
- 데이터에서 추출된 패턴을 기반으로 확률을 해석하는데 사용된다.
- (회귀에서 L2노름을 최소화) 조건부기대값 E[y|x]을 추정
 
### 기대값
- 확률분포가 주어지면 데이터를 분석하는 데 사용 가능한 여러 종류의 통계적 범함수
- 기대값은 데이터를 대표하는 통계량이면서 동시에 확률분포를 통해 다른 통계적 범함수를 계산하는데 사용


### 몬테카를로 샘플링
- 기계학습의 많은 문제들은 확률분포를 명시적으로 모를 때가 대부분이다.
- 확률분포를 모를 때 데이터를 이용하여 기대값을 계산하려면 몬테카를로 샘플링 방법을 사용해야한다.
- 독립추출만 보장된다면 대수의법칙에 의해 수렴성을 보장한다.


## 3. 통계학
- `근사적`으로 `확률분포`를 `추정`
- 데이터가 특정 확률분포를 따른다로 선험적으로 가정한 후 그 분포를 결정하는 모수를 추정하는 방법을 모수적방법론이라 한다.
- 특정 확률분포를 가정하지 않고 데이터에 따라 모델의 구조 및 모수의 개수가 유연하게 바뀌면 비모수 방법론이라 부른다.
- 확률분포를 가정하는 방법 : 우선 히스토그램을 통해 모양을 관찰합니다
    - 데이터가 2개의값(0또는1)만 가지는경우→베르누이분포
    - 데이터가 n개의 이산적인 값을 가지는경우→카테고리분포
    - 데이터가 [0,1]사이에서 값을 가지는경우→베타분포
    - 데이터가 0이상의 값을 가지는경우→감마분포,로그정규분포등
    - 데이터가 R 전체에서 값을 가지는경우→정규분포,라플라스분포등
    
### 데이터로 모수를 추정

#### 표본평균
\\( \bar X = \frac{1}{N}\sum_{i=1}^NX_i \\)

#### 표본분산 
\\( S^2 = \frac{1}{N-1}\sum_{i=1}^N(X_i-\bar X)^2 \\)

- 통계량의 확률분포를 표집분포라 부르며 특히 표본평균의 표분분포는 N이 커질수록 정규분포 \\( N(u,\sigma^2/N) \\)를 따른다

#### 표본편차
- 분산의 제곱근 

### 최대가능도  추정법
- 최대가능도 추정법(maximum likelihood estimation, MLE)

    \\( \hat\theta_{MLE}=argmax L(\theta;x)=argmax P(x|\theta) \\)

#### 로그가능도
- 데이터집합 X가 독립적으로 추출되었을 경우 로그가능도를 최적화한다. 
- 로그가능도를 사용하는 이유 :
    - 데이터의 숫자가 수억 단위가 된다면 컴퓨터의 정확도로는 가능도를 계산하기 힘들다
    - 경사하강법으로 가능도를 최적화할때 미분연산을 사용하게 되는데, 로그가능도를 사용하면 연산량을 O(n^2)에서 O(n)으로 줄어든다
    - 대게의 손실함수의 경우 경사하강법을 사용하므로 음의 로그가능도(negative log-likelihood)를 최적화
    
### 확률분포의 거리
- 기계학습에서 사용되는 손실함수들은 모델이 학습하는 확률분포와 데이터에서 관찰되는 확률분포의 거리를 통해 유도
- 데이터공간에 두 개의 확률분포 P(x), Q(x)가 있을 경우 두 확률분포 사이의 거리를 계산할 때 다음과 같은 함수 사용
    - 총변동 거리 (Total Variation Distans, TV)
    - `쿨백-라이블러 발산` (Kullback-Leibler Divergence, KL)
    - 바슈타인 거리 (Warrserstein Distance)
    
<br>

## 4. 베이즈 통계학

### 조건부 확률이란 
- 베이즈 정리는 조건부확률을 이용하여 정보를 갱신하는 방법
- 유용한 통계적 해석을 제공하지만, `인과관계`를 추론할 때 함부로 사용하면 안됨
    - 인과관계를 알아내기 위해서는 `중첩요인`의 효과를 제거하고 원인에 해당하는 변수만의 인과관계를 계산해야함 

    \\( P(A\cap B) = P(B)P(A|B) \\
    P(B|A)=\frac{P(A\cap B)}{P(A)}=P(B)\frac{P(A|B)}{P(A)} \\)
    
### 베이즈 정리

\\( P(\theta |D) = P(\theta)\frac{P(D|\theta)}{P(D)} \\)  


\\( P(\theta |D) : 사후확률(posterior) \\         
P(\theta) : 사전확률(prior) \\
P(D|\theta) : 가능도(likelihood) \\
P(D) : Evidence \\)

<br>

_예제 :_
```
COVID-99 의 발병률이 10% 로 알려져있다. COVID-99 에 실제로 걸렸을 때 검진될 확률은 99%, 실제로 걸리지 않았을 때 오검진될 확률이 1% 라고 할 때, 어떤 사람이 질병에 걸렸다고 검진결과가 나왔을 때 정말로 COVID- 99 에 감염되었을 확률은?

사전확률 = 0.1
사전확률의 부정 = 0.9
가능도 = 0.99
가능도의 부정= 0.01

Evidence = 0.99 * 0.1 + 0.01 * 0.9 = 0.108
사후확률 = 0.1*0.99/0.108 = 약0.916
```
->`오탐률(false alarm)이 오르면 정밀도(precision)가 떨어진다` 

### 베이즈 정리를 통한 정보의 갱신 `(중요)`
- 베이즈 정리를 통해 새로운 데이터가 들어왔을 때 `앞서 계산한 사후확률`을 `사전확률`로 사용하여 `갱신된 사후확률`을 계산할 수 있다.

<br>

## 5. CNN

### Convolution 연산
- 다층신경망(MLP)은 각 뉴런들이 선형모델과 활성함수로 모두 연결된 구조
- Convolution은 커널(Kernel)을 입력벡터 상에서 움직여가면서 선형모델과 합성함수가 적용되는 구조
- 수학적의미
    - 신호를 커널을 이용해 국소적으로 증폭 또는 감지 -> 정보추출 or 필터링
    
    continuous : \\(\lbrack f * g \rbrack(x) = \int_{\mathbb{R}^d} f(z)g(x-z)dz = \lbrack g * f \rbrack(x) \\)
    
    discete : \\(\lbrack f * g \rbrack(i) = \sum_{a \in \mathbb Z^d} f(a)g(i-a) = \lbrack g * f \rbrack(i) \\)  


- 커널 : 정의역 내에서 움직여도 변하지 않고 주어진 신호에 국소적으로 적용

### 다양한 차원에서 Convolution 
- 1차원: \\(\lbrack f * g \rbrack(i) = \sum_{p=1}^d f(p)g(i + p) \\)
- 2차원: \\(\lbrack f * g \rbrack(i, j) = \sum_{p,q} f(p,q)g(i + p, j + q) \\)
- 3차원: \\(\lbrack f * g \rbrack(i, j, k) = \sum_{p,q,r} f(p,q,r)g(i + p, j + q, k + r) \\)

__`커널의 위치는 변하지 않는다`__

### 2차원 Convolution 
- 입력 크기 \\((H, W)\\), 커널 크기 \\((K_H, K_W)\\), 출력 크기 \\((O_H, O_W)\\)  
\\( O_H = H - K_H + 1 \\)  
\\( O_W = W - K_W + 1 \\)  
ex) 입력 : 28x28, 커널 : 3x3 -> 26x26  


- 채널이 여러개인 경우 convolution을 채널 수 만큼 적용  
\\( (K_H,K_W,C) * (H,W,C) \rightarrow (O_H,O_W,1) \\)  
\\( (K_H,K_W,C) \times O_C * (H,W,C) \rightarrow (O_H,O_W,O_C) \\)

### Convolution 연산의 역전파
\\( \frac{\partial}{\partial x} \lbrack f * g \rbrack (x) = \frac{\partial}{\partial x} \int_{\mathbb R^d} f(y) g(x-y) dy \\)

\\( = \int_{\mathbb R^d} f(y) \frac{\partial}{\partial x} g(x-y) dy \\) 

\\( = \lbrack f * g' \rbrack (x) \\)

<br>

## 6. RNN
- 시퀀스 데이터 : 소리, 문자열, 주가 등의 데이터를 시퀀스 데이터라 한다

### 시퀀스
- 이전 시퀀스의 정보를 가지고 앞으로 발생할 데이터의 확률분포를 다루기 때문에 조건부확률 이용
- 시퀀스 데이터를 다루기 위해선 길이가 가변적인 데이터를 다룰 수 있는 모델이 필요하다

    \\( P(X_1,...,X_t) = P(X_t \vert X_1,...,X_{t-1})P(X_1,...,X_{t-1}) \\)

    \\( = \prod_{s=1}^t P(X_s \vert X_1,...,X_{s-1}) \\) 
    
### Recurrent Neural Network
- 가장 기본적인 RNN모형은 MLP와 유사
- RNN은 이전 순서의 잠재변수와 현재의 입력을 활용하여 모델링

    \\( H_t \\) : 잠재변수  
    \\( \sigma \\) : 활성화함수  
    \\( X_tW^{(1)} \\) : 가중치 행렬  
    \\( b^{(1)} \\) : bias

    \\( O_t = HW^{(2)} + b^{(2)} \\)  
    \\( H_t = \sigma(X_tW^{(1)} + b^{(1)}) \\) 
    
    \\( \rightarrow H_t = \sigma(X_tW_X^{(1)} + H_{t-1}W_H^{(1)} + b^{(1)}) \\)  
    
    - 이를 Backpropagation Through Time(BPTT) 이라 하며 RNN 의 역전파 방법  
      
      
- 길어지는 경우 역전파 알고리즘의 계산이 불안정 해지므로 길이를 끊는 것이 필요 (BPTT)
- 이를 해결하기 위해 RSTM과 GRU라는 RNN 네트워크 등장



<br><br>


## 1주차 강의를 마치며...

```
강의량에 치여 여유시간이 거의 없었다.... 심화문제도 해결해보면서 공부를 하려고했지만 생각보다 시간이 오래걸렸다. 
강의를 이해하고 정리를 하는 과정에서 오래걸린듯하다.
정리를 위한 마크다운에 적응하는것부터(특히 수식쓰는법) git, page등 환경세팅까지 온보딩시간에 미리했어야했는데라는 아쉬움이 생겼다. 
주말에는 깃허브페이지와 심화문제에 건드려볼 예정
다음주부터는 계획을 좀 타이트하게 짜고 여유시간에 강의외의 공부를... 할 수 있겠지?
```
