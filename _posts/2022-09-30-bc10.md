---
layout: single
title:  "Week2-day5"
toc: true
toc_sticky: true

use_math: true
---

PyTorch

<br>

## [ special ]
- 

## 1. PyTorch Troubleshooting

### OOM
- 왜 발생했는지 알기 어려움
- Error backtracking이 이상한데로 감
- 메모리의 이전상황의 파악이 어려움
- 어디서 발생했는지 알기 어려움

### GPUUtill 사용하기
- nvidia-smi 처럼 GPU의 상태를 보여주는 모듈
- Colab은 환경에서 GPU 상태 보여주기 편함
- iter마다 메모리가 늘어나는지 확인

###  torch.cuda.empty_cache()
- 사용되지 않은 GPU상 cache를 정리
- 가용 메모리를 확보
- del과는 구분이 필요

### del
- 필요가 없어진 변수는 적절한 삭제가 필요함
- python의 메모리 배치 특성상 loop이 끝나도 메모리를 차지함

### batch 사이즈
- 학습시 OOM이 발생했다면 batch 사이즈를 1로 해서 실험해보기

### torch.no_grad()
- Inference 시점에서는 torch.no_grad()구문을 사용
- backward pass으로 인해 쌓이는 메모리에서 자유로움

### 그 외
- CNN의 대부분의 에러는 키그가 안 맞아서 생기는 경우
    - (Torchsummary 등으로 사이즈를 맞출 것)
