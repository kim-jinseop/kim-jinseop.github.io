---
layout: single
title:  "Week5-day2"
toc: true
toc_sticky: true

use_math: true
---

CV - Multi-modal Learing

<br>

## [ special ]

# - Multi-modal tasks (1) - Visual data & Test

## 1. Text embedding
- dense vectors
- word2vec
    - skip-gram model
    
## 2. Joint embedding
- Application
    - Image tagging

## 3. Cross modal translation
- Show, attend, and tell
    - Attention (soft)
    - Inference
- Text-to-image by generative model

## 4. Cross modal reasoning
- Visual question answering
    - Nultiple streams
    - Joint embedding


# - Multi-modal tasks (2) - Visual data & Audio

## 1. Sound representation
- Fourirt transform
    - Short-time Fourier transform (STFT)
- Sound representation 
    - Spectrogram

## 2. Joint embedding
- SoundNet
    - audio representation
    - teacher-student
    
## 3. Cross modal translation
- Speech2Face
    - Module networks
    - Training
- Image-to-speech synthesis
    - Module networks
    
## 4. Cross modal reasoning
- Application
    - Sound source localization
- Looking to listen at the cocktail party
    - Visual stream
    - Audio stream

<br>  

# - Image Captioning

## Encoder - CNN


```python
import torch.nn as nn
```


```python
class Encoder(nn.Module) :
    def __init__ (self, encoded_image_size=14) :
        super(Encoder, self).__init__()
        self.enc_image_size = encoded_image_size
        
        resnet = torchvision.models.resnet101(pretrained=True)
        
        modules = list(resnet.children())[:-2]
        self.resnet = nn.Sequential(*modules)
```

## Decoder - RNN
- Decoder(with attention Module)
- Beam Search
