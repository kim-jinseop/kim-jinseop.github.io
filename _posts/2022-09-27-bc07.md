---
layout: single
title:  "Week2-day2"
toc: true
toc_sticky: true

use_math: true
---

PyTorch

<br>

## 1. AutoGrad & Optimizer

### torch.nn.Module
- 딥러닝을 구성하는 Layer의 base class
- Input, Output, Forward, Backward 정의 
- 학습대상 parameter(tensor) 정의

### nn.Parameter
- nn.Mondule 내에 `attribute가 될 때`는 required_grad = True 로 지정되어 학습 대상이 되는 Tensor
    - AutoGrad
- 대부분 layer 에는 weights 값들이 지정되어 있다. 

### Backward
- Layer에 있는 Parameter들의 미분을 수행
- Forward의 결과값 (model의 output=예측치)과 실제값간의 차이(loss)에 대해 미분을 수행
- 해당 값으로 parameter 업데이트

### Backward form the scratch
- 실제 backward는 Module단계에서 직접 지정 가능
- Module에서 backward와 optimizer 오버라이딩
- optimize : update, backward : 미분 

<br>
## 2. PyTorch Dataset

### Dataset 클래스
- 데이터 입력 형태를 정의하는 클래스
- Image, Text, Audio 등에 따른 입력정의
- 생성시 유의점 : 
    - 데이터 형태에 따라 각함수를 다르게 정의함
    - 모든 것을 데이터 생성 시점에 처리할 필요는 없다
        - image의 Tenser 변화는 학습에 필요한 시점에 변환
    - 데이터 셋에 대한 표준화된 처리방법 제공 필요
    
### DataLoader 클래스
- Data의 Batch를 생성해주는 클래스
- 학습직전 데이터의 변환을 책임
- Tensor로 변환 + Batch 처리가 메인 업무
- 병렬적인 데이터 전처리 코드의 고민 필요
